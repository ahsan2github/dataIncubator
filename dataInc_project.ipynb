{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as py_datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=requests.get(\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=RU1K3VX6KM5GVHKJ\")\n",
    "print(\"status code: \", data.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdata = json.loads(data.content)\n",
    "with open('alphavantage_series.txt', 'w') as ofile:\n",
    "    json.dump(jdata, ofile)\n",
    "    ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alphavantage_series.txt', 'r') as ifile:\n",
    "    jada = json.load(ifile)\n",
    "    ifile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data.status_code == 200: \n",
    "    jdata = json.loads(data.content)\n",
    "    meta_data = jdata['Meta Data']\n",
    "    time_series_dict = jdata['Time Series (Daily)'];\n",
    "    dates = list(time_series_dict.keys());\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['date'] = [pd.to_datetime(x) for x in dates]\n",
    "    df['open'] = [np.float64(time_series_dict[x]['1. open']) for x in dates]\n",
    "    df['high'] = [np.float64(time_series_dict[x]['2. high']) for x in dates]\n",
    "    df['low'] = [np.float64(time_series_dict[x]['3. low']) for x in dates]\n",
    "    df['close'] = [np.float64(time_series_dict[x]['4. close']) for x in dates]\n",
    "    df['volume'] = [np.float64(time_series_dict[x]['5. volume']) for x in dates]\n",
    "    df['symbol'] = meta_data['2. Symbol']\n",
    "    df.index = df['date']\n",
    "else:\n",
    "    print(\"Error in retrieving data!, status code: \", data.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Status Code: {0}\".format(data.status_code))\n",
    "print(df['2018-04-26'])\n",
    "fig, ax = plt.subplots(2,1, sharex='col')\n",
    "fig.set_size_inches(12, 3.5)\n",
    "ax[0].plot(df.index[0:11], df['open'][0:11], 'og')\n",
    "ax[0].plot(df.index[0:11], df['close'][0:11], 'or')\n",
    "ax[0].fill_between(df.index[0:11], 90, df['open'][0:11], facecolor='darkturquoise', alpha=0.15)\n",
    "ax[0].set_ylim([90, 100])\n",
    "ax[0].set_ylabel('open/close', fontsize=12)\n",
    "ax[0].legend(['open', 'close'], frameon=0, fontsize=12, loc='upper left')\n",
    "\n",
    "ax[1].plot(df.index[0:11], df['low'][0:11], 'or')\n",
    "ax[1].plot(df.index[0:11], df['high'][0:11], 'og')\n",
    "ax[1].fill_between(df.index[0:11], 89, df['low'][0:11], facecolor='orange', alpha=0.15)\n",
    "ax[1].set_ylabel(\"low/high\", fontsize=12)\n",
    "ax[1].legend(['low', 'high'], frameon=0, fontsize=12, loc='upper left')\n",
    "ax[1].set_ylim([89, 100])\n",
    "ax[1].tick_params(axis='x', rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-892abb4b7db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data Size in MB: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mtseries_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Data Size in MB: {0}\".format(df.memory_usage(index=True).sum()/1024/1024))\n",
    "\n",
    "class tseries_data:\n",
    "    def __init__(self, source, source_dates):\n",
    "        self.dates = np.array(source_dates.map(str).tolist())\n",
    "        self.dates = self.dates.flatten()\n",
    "        self.tseries = source.as_matrix().flatten()\n",
    "        self.nrow = self.tseries.shape\n",
    "        self.nrow = self.nrow[0]\n",
    "        \n",
    "    def get_series(self, series_len, date_yes = False):\n",
    "        if series_len > self.nrow:\n",
    "            print(\"Requested series is longer than existing series\")\n",
    "            return\n",
    "        else:\n",
    "            begin = np.random.rand()\n",
    "            begin = np.int(begin * (self.nrow - series_len - 1))\n",
    "            x_temp = self.tseries[begin+1:begin+series_len+1]\n",
    "            x = x_temp[::-1]\n",
    "            y_temp = self.tseries[begin:begin+series_len]\n",
    "            y = y_temp[::-1]\n",
    "            date_series_temp = self.dates[begin:begin+series_len+1]\n",
    "            date_series = date_series_temp[::-1]\n",
    "            if date_yes:\n",
    "                return np.reshape(x, [-1, series_len, 1]), np.reshape(y, [-1, series_len, 1]), np.reshape(date_series, [-1, series_len+1, 1])\n",
    "            else:\n",
    "                return np.reshape(x, [-1, series_len, 1]), np.reshape(y, [-1, series_len, 1]) \n",
    "        \n",
    "    def get_latest_series(self, series_len, date_yes = False):\n",
    "        if series_len > self.nrow:\n",
    "            print(\"Requested series is longer than existing series\")\n",
    "            return\n",
    "        else:\n",
    "            x_temp = self.tseries[1:series_len+1]\n",
    "            x = x_temp[::-1]\n",
    "            y_temp = self.tseries[0:series_len]\n",
    "            y = y_temp[::-1]\n",
    "            date_series_temp = self.dates[0:series_len+1]\n",
    "            date_series = date_series_temp[::-1]\n",
    "        if date_yes:\n",
    "            return np.reshape(x, [-1, series_len, 1]), np.reshape(y, [-1, series_len, 1]), np.reshape(dates, [-1, series_len+1, 1])\n",
    "        else:\n",
    "            return np.reshape(x, [-1, series_len, 1]), np.reshape(y, [-1, series_len, 1])\n",
    "        \n",
    "    def get_batch(self, batch_size, series_len, date_yes = False):\n",
    "        if series_len > self.nrow:\n",
    "            print(\"Requested series is longer than existing series\")\n",
    "            return\n",
    "        else:\n",
    "            batch_x = np.zeros([series_len, batch_size])\n",
    "            batch_y = np.zeros([series_len, batch_size])\n",
    "            batch_date = np.empty([series_len+1, batch_size], dtype=np.object_)\n",
    "            for ii in range(batch_size):\n",
    "                x, y, d = self.get_series(series_len, 1)\n",
    "                batch_x[:, ii], batch_y[:,ii], batch_date[:, ii] = x.flatten(), y.flatten(), d.flatten()\n",
    "            if date_yes:   \n",
    "                return np.reshape(batch_x, [-1, series_len, 1]), np.reshape(batch_y, [-1, series_len, 1]), np.reshape(batch_date, [-1, series_len+1, 1]) \n",
    "            else:\n",
    "                return np.reshape(batch_x, [-1, series_len, 1]), np.reshape(batch_y, [-1, series_len, 1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd = tseries_data(df['open'], df.index)\n",
    "series_len = 50\n",
    "x,y = tsd.get_batch(1,10)\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "learning_rate = 0.0001\n",
    "n_train_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xx = tf.placeholder(tf.float64, [None, series_len, n_inputs])\n",
    "yy = tf.placeholder(tf.float64, [None, series_len, n_outputs])\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "     tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "     output_size=n_outputs)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, xx, dtype=tf.float64)\n",
    "loss = tf.reduce_mean(tf.square(outputs - yy)) \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(n_train_iter):\n",
    "        \n",
    "        x_series, y_series = tsd.get_series(series_len)\n",
    "        sess.run(train, feed_dict={xx: x_series, yy: y_series})\n",
    "        \n",
    "        if iteration % 100 == 0:            \n",
    "            mse = loss.eval(feed_dict={xx: x_series, yy: y_series})\n",
    "            print(iteration, \"\\t MSE Error:\", mse)\n",
    "    test_x, test_y, test_date = tsd.get_latest_series(series_len, True)\n",
    "    y_pred = sess.run(outputs, feed_dict={xx: test_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = test_date.flatten()[::-1]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(12, 3.5)\n",
    "ax.plot(test_date[0:-1], test_x.flatten()[::-1], 'or')\n",
    "ax.plot(test_date[1:], test_y.flatten()[::-1], 'og')\n",
    "ax.plot(test_date[1:], y_pred.flatten()[::-1], '^b')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
